{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7635efc2-d906-42f1-aa0c-3341c3d3c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25fd46d7-3dfd-437c-b996-14401026b323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01665119-effc-4d77-9b16-3eaf7198b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Truth_Seeker_Model_Dataset.csv'\n",
    "file_path2 = 'Features_For_Traditional_ML_Techniques.csv'\n",
    "file_path3 = 'Downloads/Truth_Seeker_Model_Dataset_With_TimeStamps 1.xlsx'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "df3 = pd.read_excel(file_path3)\n",
    "\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "df2 = df2.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "df3 = df3.drop(columns=[\"Unnamed: 0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06f1b212-5a11-4de7-81c2-6d24f887d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7c5ed5e-dcd7-4f61-b187-8c66ef931878",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83855f17-2df8-49b4-ab63-f76872ebdd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from transformers import *  # this is HuggingFace library\n",
    "import tensorflow as tf\n",
    "#from transformers import BertTokenizer, TFBertModel, BertConfig\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertConfig, TFDistilBertModel\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ba8989b-3f0f-4bbb-817f-2e416a3e2d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at C:\\Users\\T2330114\\.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\T2330114\\.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\tokenizer_config.json\n",
      "loading file tokenizer.json from cache at C:\\Users\\T2330114\\.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\tokenizer.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\T2330114\\.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\T2330114\\.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\T2330114\\.cache\\huggingface\\hub\\models--distilbert-base-uncased\\snapshots\\12040accade4e8a0f71eabdb258fecc2e7e948be\\model.safetensors\n",
      "Loaded 66,362,880 parameters in the TF 2.0 model.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# this will download the BERT Tokenizer\n",
    "#bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")  \n",
    "# this will download the BERT Trained Model\n",
    "# output_hidden_states=False, as we are training & not interested in output state.\n",
    "#config = BertConfig.from_pretrained(\"bert-base-uncased\",output_hidden_states=False) # dropout=0.2, attention_dropout=0.2\n",
    "#bert_model = TFBertModel.from_pretrained('bert-base-uncased', config=config)\n",
    "\n",
    "# Download the DistilBERT Tokenizer\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Download the DistilBERT Trained Model\n",
    "# output_hidden_states=False is the default for DistilBert, so it's not strictly necessary to set it.\n",
    "distilbert_config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\") # You can add config parameters here if needed\n",
    "distilbert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased', config=distilbert_config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "747afbc8-f8cd-4e42-a1ed-2bec6d55a207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def clean_text(temp):\n",
    "    temp=re.sub(\"@\\S+\", \" \", temp)\n",
    "    temp=re.sub(\"https*\\S+\", \" \", temp)\n",
    "    temp=re.sub(\"#\\S+\", \" \", temp)\n",
    "    temp=re.sub(\"\\'\\w+\", '', temp)\n",
    "    temp=re.sub(r'\\w*\\d+\\w*', '', temp)\n",
    "    temp=re.sub('\\s{2,}', \" \", temp)\n",
    "   \n",
    "    return temp.strip()\n",
    "\n",
    "df['tweet_clean'] = df['tweet'].apply(clean_text)\n",
    "df['stat'] = df['statement'].apply(clean_text)\n",
    "df['auth'] = df['author'].apply(clean_text)\n",
    "df['mank'] = df['manual_keywords'].apply(clean_text)\n",
    "df['fivlab'] = df['5_label_majority_answer'].apply(clean_text)\n",
    "df['thrlab'] = df['3_label_majority_answer'].apply(clean_text)\n",
    "#sentences = df['tweet_clean'] + \" \"+ df['stat'] + \" \" + df['auth'] + \" \" + df['mank'] + \" \" + df['fivlab'] + \" \" + df['thrlab'] \n",
    "\n",
    "sentences = df['tweet_clean'] + \" \"+ df['stat'] + \" \" + df['auth'] + \" \" + df['mank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a715471-0e42-481f-b461-bb31f0359827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 134198/134198 [03:32<00:00, 630.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in tqdm(sentences):\n",
    "    bert_inp=distilbert_tokenizer.encode_plus(sent,add_special_tokens = True,truncation=True,max_length =28,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids.append(bert_inp['input_ids'])\n",
    "    attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "target = np.array(df['BinaryNumTarget'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66d12058-52a7-4b04-8f16-6df32e492e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distilbert_tokenizer.convert_ids_to_tokens(101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c800e9f-0a6d-4b81-bc5b-340c242f463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test,train_mask,test_mask=train_test_split(input_ids,target,attention_masks,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8356c5b4-01a3-4d0b-8dfb-8435cb96ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMai  multiple                 66362880  \n",
      " nLayer)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,362,880\n",
      "Trainable params: 66,362,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "distilbert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c65a6c5-a4f9-4412-bc09-d9205f7fa973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_token (InputLayer)       [(None, 28)]         0           []                               \n",
      "                                                                                                  \n",
      " masked_token (InputLayer)      [(None, 28)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_distil_bert_model_1 (TFDist  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n",
      " ilBertModel)                   ast_hidden_state=(N               'masked_token[0][0]']           \n",
      "                                one, 28, 768),                                                    \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 28, 16)      37344       ['tf_distil_bert_model_1[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 16)          0           ['bidirectional_1[0][0]']        \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 8)            136         ['global_max_pooling1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 8)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            9           ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66,400,369\n",
      "Trainable params: 37,489\n",
      "Non-trainable params: 66,362,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dense, Dropout, Flatten, Concatenate, GlobalMaxPool1D , Bidirectional,GRU\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Textual Input\n",
    "# text_input = Input(shape=(max_sequence_length,), name='text_input')\n",
    "# embedding = Embedding(input_dim=max_num_words, output_dim=embedding_dim, input_length=max_sequence_length)(text_input)\n",
    "input_ids_in = tf.keras.layers.Input(shape=(28,), name='input_token', dtype='int32')\n",
    "input_masks_in = tf.keras.layers.Input(shape=(28,), name='masked_token', dtype='int32') \n",
    "embedding_layer = distilbert_model(input_ids_in, attention_mask=input_masks_in)[0] \n",
    "gru = Bidirectional(GRU(8, return_sequences=True, dropout=0.1, recurrent_dropout=0))(embedding_layer)\n",
    "pooling = GlobalMaxPool1D()(gru)\n",
    "X = Dense(8, activation='relu')(pooling)\n",
    "X = Dropout(0.2)(X)\n",
    "X = Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "model = Model(inputs=[input_ids_in, input_masks_in], outputs=X)\n",
    "\n",
    "\n",
    "for layer in distilbert_model.layers[:3]:  \n",
    "    layer.trainable = False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c9b819a-410a-4d8f-bfab-5df238e14ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_path = \"finaltraining_1grudistillbert/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcd290b5-4a3d-47d4-be70-ef954308540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "3355/3355 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.8429\n",
      "Epoch 1: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 133s 37ms/step - loss: 0.3774 - accuracy: 0.8429 - val_loss: 0.2487 - val_accuracy: 0.9007\n",
      "Epoch 2/8\n",
      "3354/3355 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.8942\n",
      "Epoch 2: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 122s 36ms/step - loss: 0.2724 - accuracy: 0.8941 - val_loss: 0.2177 - val_accuracy: 0.9145\n",
      "Epoch 3/8\n",
      "3355/3355 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9058\n",
      "Epoch 3: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 123s 37ms/step - loss: 0.2437 - accuracy: 0.9058 - val_loss: 0.2037 - val_accuracy: 0.9187\n",
      "Epoch 4/8\n",
      "3355/3355 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9104\n",
      "Epoch 4: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 124s 37ms/step - loss: 0.2278 - accuracy: 0.9104 - val_loss: 0.1912 - val_accuracy: 0.9243\n",
      "Epoch 5/8\n",
      "3354/3355 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9162\n",
      "Epoch 5: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 124s 37ms/step - loss: 0.2173 - accuracy: 0.9162 - val_loss: 0.1909 - val_accuracy: 0.9254\n",
      "Epoch 6/8\n",
      "3354/3355 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9187\n",
      "Epoch 6: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 121s 36ms/step - loss: 0.2097 - accuracy: 0.9186 - val_loss: 0.1881 - val_accuracy: 0.9241\n",
      "Epoch 7/8\n",
      "3354/3355 [============================>.] - ETA: 0s - loss: 0.2040 - accuracy: 0.9210\n",
      "Epoch 7: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 124s 37ms/step - loss: 0.2040 - accuracy: 0.9210 - val_loss: 0.1820 - val_accuracy: 0.9289\n",
      "Epoch 8/8\n",
      "3355/3355 [==============================] - ETA: 0s - loss: 0.2011 - accuracy: 0.9214\n",
      "Epoch 8: saving model to finaltraining_1grudistillbert\\cp.ckpt\n",
      "3355/3355 [==============================] - 123s 37ms/step - loss: 0.2011 - accuracy: 0.9214 - val_loss: 0.1885 - val_accuracy: 0.9240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=model.fit([X_train,train_mask],y_train,batch_size=32,epochs=8,validation_data=([X_test,test_mask],y_test),callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40c00b75-7b3b-4cd0-a65a-24fcb8c16869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint', 'cp.ckpt.data-00000-of-00001', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "208d4f24-8a22-4caf-863a-86f7afa759d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1b5fb594700>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8d64946-de64-4bbf-b84c-44150fd8aead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839/839 - 18s - loss: 0.1885 - accuracy: 0.9240 - 18s/epoch - 22ms/step\n",
      "Restored model, accuracy: 92.40%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate([X_test,test_mask],y_test, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33a005dc-0e5d-41fc-9131-910dc7860c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839/839 [==============================] - 20s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_prob = model.predict([X_test,test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b24c363a-d831-444d-be1f-1b68f7a3498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9239940387481371\n",
      "Test Precision: 0.8997812414547444\n",
      "Test Recall: 0.9582119976703553\n",
      "F1-score: 0.9280778451558314\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test Precision: {precision}\")\n",
    "print(f\"Test Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca2ffcaf-2faf-44f6-8a9b-41ad504b1028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 575.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "predict_sent = sentences[:20]\n",
    "\n",
    "input_ids2=[]\n",
    "attention_masks2=[]\n",
    "\n",
    "\n",
    "for sent in tqdm(predict_sent):\n",
    "    bert_inp=distilbert_tokenizer.encode_plus(sent,add_special_tokens = True,truncation=True,max_length =28,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids2.append(bert_inp['input_ids'])\n",
    "    attention_masks2.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids_predict=np.asarray(input_ids2)\n",
    "attention_masks_predict=np.array(attention_masks2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e381ede8-c1c8-4edf-b1fd-0b7897b724b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  label  \n",
       "0  December 31, 2017    0.0  \n",
       "1  December 31, 2017    0.0  \n",
       "2  December 30, 2017    0.0  \n",
       "3  December 29, 2017    0.0  \n",
       "4  December 25, 2017    0.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preddf1 = pd.read_csv('ISOT_Fake.csv') ## Fake\n",
    "\n",
    "preddf1['label'] = 0.0\n",
    "\n",
    "preddf2 = pd.read_csv('ISOT_True.csv') ##Real\n",
    "\n",
    "preddf2['label'] = 1.0\n",
    "\n",
    "preddf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eda11376-c023-4905-9baf-48c9b15f7778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  label  \n",
       "0  December 31, 2017     1.0  \n",
       "1  December 29, 2017     1.0  \n",
       "2  December 31, 2017     1.0  \n",
       "3  December 30, 2017     1.0  \n",
       "4  December 29, 2017     1.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "628d0c5e-3c85-4f56-856a-23faba97e768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ben Stein Calls Out 9th Circuit Court: Committ...</td>\n",
       "      <td>21st Century Wire says Ben Stein, reputable pr...</td>\n",
       "      <td>US_News</td>\n",
       "      <td>February 13, 2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump drops Steve Bannon from National Securit...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Donald T...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 5, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puerto Rico expects U.S. to lift Jones Act shi...</td>\n",
       "      <td>(Reuters) - Puerto Rico Governor Ricardo Rosse...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>September 27, 2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOPS: Trump Just Accidentally Confirmed He Le...</td>\n",
       "      <td>On Monday, Donald Trump once again embarrassed...</td>\n",
       "      <td>News</td>\n",
       "      <td>May 22, 2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump heads for Scotland to reopen a go...</td>\n",
       "      <td>GLASGOW, Scotland (Reuters) - Most U.S. presid...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>June 24, 2016</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Ben Stein Calls Out 9th Circuit Court: Committ...   \n",
       "1  Trump drops Steve Bannon from National Securit...   \n",
       "2  Puerto Rico expects U.S. to lift Jones Act shi...   \n",
       "3   OOPS: Trump Just Accidentally Confirmed He Le...   \n",
       "4  Donald Trump heads for Scotland to reopen a go...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  21st Century Wire says Ben Stein, reputable pr...       US_News   \n",
       "1  WASHINGTON (Reuters) - U.S. President Donald T...  politicsNews   \n",
       "2  (Reuters) - Puerto Rico Governor Ricardo Rosse...  politicsNews   \n",
       "3  On Monday, Donald Trump once again embarrassed...          News   \n",
       "4  GLASGOW, Scotland (Reuters) - Most U.S. presid...  politicsNews   \n",
       "\n",
       "                  date  label  \n",
       "0    February 13, 2017    0.0  \n",
       "1       April 5, 2017     1.0  \n",
       "2  September 27, 2017     1.0  \n",
       "3         May 22, 2017    0.0  \n",
       "4       June 24, 2016     1.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combine = pd.concat([preddf1, preddf2], ignore_index=True)\n",
    "\n",
    "combine = combine.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3507f689-5863-4a22-beb1-1cd3477c467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_text(temp):\n",
    "    temp=re.sub(\"@\\S+\", \" \", temp)\n",
    "    temp=re.sub(\"https*\\S+\", \" \", temp)\n",
    "    temp=re.sub(\"#\\S+\", \" \", temp)\n",
    "    temp=re.sub(\"\\'\\w+\", '', temp)\n",
    "    temp=re.sub(r'\\w*\\d+\\w*', '', temp)\n",
    "    temp=re.sub('\\s{2,}', \" \", temp)\n",
    "    return temp.strip()\n",
    "\n",
    "\n",
    "combine['tile'] = combine['title'].apply(clean_text)\n",
    "combine['text_clean'] = combine['text'].apply(clean_text)\n",
    "combine['sub'] = combine['subject'].apply(clean_text)\n",
    "combine['dat'] = combine['date'].apply(clean_text)\n",
    "\n",
    "\n",
    "#sentences3 = combine['tile'] + \" \" + combine['text_clean'] + \" \" + combine['sub'] + \" \" + combine['dat']\n",
    "sentences3 = combine['tile'] + \" \" + combine['text_clean'] + \" \" + combine['sub']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a7e6955-b92c-49f0-a8a1-29beebed8022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 44898/44898 [08:21<00:00, 89.61it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ids3=[]\n",
    "attention_masks3=[]\n",
    "\n",
    "\n",
    "for sent in tqdm(sentences3):\n",
    "    bert_inp=distilbert_tokenizer.encode_plus(sent,add_special_tokens = True,truncation=True,max_length =28,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids3.append(bert_inp['input_ids'])\n",
    "    attention_masks3.append(bert_inp['attention_mask'])\n",
    "\n",
    "new_input_ids=np.asarray(input_ids3)\n",
    "new_attention_mask=np.array(attention_masks3)\n",
    "new_labels = np.array(combine['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47502126-6f0f-4734-82b2-dd8cec1b99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_trainnew, X_testnew, y_trainnew, y_testnew,train_masknew,test_masknew=train_test_split(new_input_ids,new_labels,new_attention_mask,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a51090bd-c58e-4e65-9b2a-16af497465ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path2 = \"finaltraining_2grudistillbert/cp.ckpt\"\n",
    "checkpoint_dir2 = os.path.dirname(checkpoint_path2)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback2 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path2,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Recompile the model with a smaller learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=2e-5),  # Smaller learning rate for fine-tuning\n",
    "    loss='binary_crossentropy',         # Same loss function as before\n",
    "    metrics=['accuracy']                # Same evaluation metrics\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07ee3109-b7a6-42fc-ad90-c0694525875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1122/1123 [============================>.] - ETA: 0s - loss: 0.6875 - accuracy: 0.6956\n",
      "Epoch 1: saving model to finaltraining_2grudistillbert\\cp.ckpt\n",
      "1123/1123 [==============================] - 54s 40ms/step - loss: 0.6874 - accuracy: 0.6956 - val_loss: 0.4733 - val_accuracy: 0.7913\n",
      "Epoch 2/7\n",
      "1122/1123 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8339\n",
      "Epoch 2: saving model to finaltraining_2grudistillbert\\cp.ckpt\n",
      "1123/1123 [==============================] - 40s 35ms/step - loss: 0.3862 - accuracy: 0.8340 - val_loss: 0.2983 - val_accuracy: 0.8754\n",
      "Epoch 3/7\n",
      "1122/1123 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.8990\n",
      "Epoch 3: saving model to finaltraining_2grudistillbert\\cp.ckpt\n",
      "1123/1123 [==============================] - 45s 40ms/step - loss: 0.2535 - accuracy: 0.8990 - val_loss: 0.1815 - val_accuracy: 0.9280\n",
      "Epoch 4/7\n",
      "1123/1123 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9362\n",
      "Epoch 4: saving model to finaltraining_2grudistillbert\\cp.ckpt\n",
      "1123/1123 [==============================] - 42s 38ms/step - loss: 0.1726 - accuracy: 0.9362 - val_loss: 0.1220 - val_accuracy: 0.9562\n",
      "Epoch 5/7\n",
      "1123/1123 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.9587\n",
      "Epoch 5: saving model to finaltraining_2grudistillbert\\cp.ckpt\n",
      "1123/1123 [==============================] - 40s 36ms/step - loss: 0.1258 - accuracy: 0.9587 - val_loss: 0.0859 - val_accuracy: 0.9703\n",
      "Epoch 6/7\n",
      "1123/1123 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9683\n",
      "Epoch 6: saving model to finaltraining_2grudistillbert\\cp.ckpt\n",
      "1123/1123 [==============================] - 41s 37ms/step - loss: 0.0988 - accuracy: 0.9683 - val_loss: 0.0663 - val_accuracy: 0.9801\n",
      "Epoch 7/7\n",
      "1123/1123 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9762\n",
      "Epoch 7: saving model to finaltraining_2grudistillbert\\cp.ckpt\n",
      "1123/1123 [==============================] - 42s 38ms/step - loss: 0.0800 - accuracy: 0.9762 - val_loss: 0.0548 - val_accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fine-tuning with new data\n",
    "history2 = model.fit(\n",
    "    [X_trainnew, train_masknew],  # New input data\n",
    "     y_trainnew,                           # New labels\n",
    "    batch_size=32,\n",
    "    epochs=7,  # Use fewer epochs for fine-tuning\n",
    "    validation_data=([X_testnew, test_masknew], y_testnew),callbacks=[cp_callback2] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be60ea7d-bfc6-4a28-84fc-157bd8fbf3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1b5fc40dab0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20731177-623b-42bb-97f6-a19f1f69fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 - 6s - loss: 0.0548 - accuracy: 0.9834 - 6s/epoch - 21ms/step\n",
      "Restored model, accuracy: 98.34%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "loss, acc = model.evaluate([X_testnew, test_masknew], y_testnew, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3454a31-be66-4b9d-ae04-900e4459b92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 9s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_prob2 = model.predict([X_testnew, test_masknew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad5f92d9-94f2-4068-a386-a17b045a9516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9834075723830735\n",
      "Test Precision: 0.9772990502663887\n",
      "Test Recall: 0.988056206088993\n",
      "F1-score: 0.982648189123093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred2 = (y_pred_prob2 > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy2 = accuracy_score(y_testnew, y_pred2)\n",
    "precision2 = precision_score(y_testnew, y_pred2)\n",
    "recall2 = recall_score(y_testnew, y_pred2)\n",
    "f12 = f1_score(y_testnew, y_pred2)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy2}\")\n",
    "print(f\"Test Precision: {precision2}\")\n",
    "print(f\"Test Recall: {recall2}\")\n",
    "print(f\"F1-score: {f12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c2392-d95a-486d-a614-d6e96ea125c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
